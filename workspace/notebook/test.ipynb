{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Define the path to the pickle file\n",
    "# pickle_file_path = 'moodtheme_test_dict.pickle'\n",
    "pickle_file_path = '../../dataset/jamendo/splits/split-2/moodtheme_test_dict.pickle'\n",
    "\n",
    "# Load the contents of the pickle file\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Print the contents of the pickle file\n",
    "print(\"Contents of the pickle file:\")\n",
    "\n",
    "print(data)\n",
    "\n",
    "# {0: \n",
    "# {'path': '24/3524.mp3', \n",
    "# 'duration': 16629.0, \n",
    "# 'tags': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "#        0., 0., 0., 0., 0.s])\n",
    "# }, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def get_genres_by_track_id(file_path, track_id):\n",
    "    with open(file_path, newline='') as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        headers = next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            if row[0] == track_id:\n",
    "                tags = row[5:]  # Assuming 'TAGS' is the 6th column and beyond\n",
    "                #genres = [tag.split('---')[1] for tag in tags if '---' in tag]\n",
    "                genres = [tag.strip() for tag in tags if '---' in tag]\n",
    "                return genres\n",
    "    return \"Track ID not found\"\n",
    "\n",
    "# Test the function\n",
    "file_path = '../../dataset/jamendo/meta/autotagging_genre.tsv'\n",
    "track_id = 'track_0000775'\n",
    "genres = get_genres_by_track_id(file_path, track_id)\n",
    "\n",
    "print(genres)\n",
    "\n",
    "\n",
    "\n",
    "# Define the path to the pickle file\n",
    "# pickle_file_path = 'moodtheme_test_dict.pickle'\n",
    "# pickle_file_path = '../../dataset/jamendo/meta/autotagging_genre.tsv'\n",
    "\n",
    "# df = pd.read_csv(pickle_file_path)\n",
    "\n",
    "# reader = csv.reader(pickle_file_path, delimiter='\\t')\n",
    "\n",
    "# track_id = \"track_0006699\"\n",
    "# track_row = df[df['TRACK_ID'] == track_id]\n",
    "\n",
    "\n",
    "# if not track_row.empty:\n",
    "#     tags = track_row['TAGS'].values[0]\n",
    "#     genres = [tag.split('---')[1] for tag in tags.split('\\t') if '---' in tag]\n",
    "#     print(genres)\n",
    "\n",
    "# else:\n",
    "#     print(\"Track ID not found\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"dac\"\n",
    "# baseline\n",
    "# dac\n",
    "\n",
    "pr_auc_path = os.path.join('../../results/', model_name ,'pr_auc_moodtheme_0.npy')\n",
    "roc_auc_path = os.path.join('../../results/', model_name ,'roc_auc_moodtheme_0.npy')\n",
    "\n",
    "pr_auc = np.load(pr_auc_path)\n",
    "roc_auc = np.load(roc_auc_path)\n",
    "# prd = np.load('../../prd.npy')\n",
    "\n",
    "print(pr_auc)\n",
    "print(roc_auc)\n",
    "# print(prd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Load the .npy files\n",
    "# feature = np.load('948.npy')\n",
    "# print(feature.shape)\n",
    "\n",
    "dac_path =  '948.hdf5'\n",
    "\n",
    "with h5py.File(dac_path, 'r') as f:\n",
    "    # Read a dataset from the file\n",
    "    # keys = list(f.keys())\n",
    "    # print(keys)\n",
    "    data = f['0']\n",
    "    print(data['dac_frame_len'][()])\n",
    "    print(data['dac_latents'][:].shape)\n",
    "    print(data['dac_rvq'][:].shape)\n",
    "\n",
    "    data = f['1']\n",
    "    print(data['dac_frame_len'][()])\n",
    "    print(data['dac_latents'][:].shape)\n",
    "    print(data['dac_rvq'][:].shape)\n",
    "    \n",
    "    data = f['2']\n",
    "    print(data['dac_frame_len'][()])\n",
    "    print(data['dac_latents'][:].shape)\n",
    "    print(data['dac_rvq'][:].shape)\n",
    "\n",
    "    data = f['3']\n",
    "    print(data['dac_frame_len'][()])\n",
    "    print(data['dac_latents'][:].shape)\n",
    "    print(data['dac_rvq'][:].shape)\n",
    "\n",
    "    data = f['4']\n",
    "    print(data['dac_frame_len'][()])\n",
    "    print(data['dac_latents'][:])\n",
    "    print(data['dac_rvq'][0].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(data['spectrogram'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mp3_files = []\n",
    "mp3_dic={}\n",
    "root_dir = \"../../dataset/jamendo/mp3\"\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.mp3'):\n",
    "                mp3_files.append(  filename.replace(\".mp3\" , \"\")  )\n",
    "                mp3_dic[filename.replace(\".mp3\" , \"\")] = dirpath\n",
    "\n",
    "print(len(mp3_files))\n",
    "\n",
    "hdf5_files = []\n",
    "root_dir = \"../../dataset/jamendo/encodec_10s\"\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.hdf5'):\n",
    "                hdf5_files.append( filename.replace(\".hdf5\" , \"\") )\n",
    "\n",
    "print(len(hdf5_files))\n",
    "\n",
    "# print(mp3_files)\n",
    "# print(hdf5_files)\n",
    "\n",
    "a = set(mp3_files)\n",
    "b = set(hdf5_files)\n",
    "\n",
    "c = a-b\n",
    "print(c)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mood/theme---action' 'mood/theme---adventure' 'mood/theme---advertising'\n",
      " 'mood/theme---background' 'mood/theme---ballad' 'mood/theme---calm'\n",
      " 'mood/theme---children' 'mood/theme---christmas'\n",
      " 'mood/theme---commercial' 'mood/theme---cool' 'mood/theme---corporate'\n",
      " 'mood/theme---dark' 'mood/theme---deep' 'mood/theme---documentary'\n",
      " 'mood/theme---drama' 'mood/theme---dramatic' 'mood/theme---dream'\n",
      " 'mood/theme---emotional' 'mood/theme---energetic' 'mood/theme---epic'\n",
      " 'mood/theme---fast' 'mood/theme---film' 'mood/theme---fun'\n",
      " 'mood/theme---funny' 'mood/theme---game' 'mood/theme---groovy'\n",
      " 'mood/theme---happy' 'mood/theme---heavy' 'mood/theme---holiday'\n",
      " 'mood/theme---hopeful' 'mood/theme---inspiring' 'mood/theme---love'\n",
      " 'mood/theme---meditative' 'mood/theme---melancholic'\n",
      " 'mood/theme---melodic' 'mood/theme---motivational' 'mood/theme---movie'\n",
      " 'mood/theme---nature' 'mood/theme---party' 'mood/theme---positive'\n",
      " 'mood/theme---powerful' 'mood/theme---relaxing' 'mood/theme---retro'\n",
      " 'mood/theme---romantic' 'mood/theme---sad' 'mood/theme---sexy'\n",
      " 'mood/theme---slow' 'mood/theme---soft' 'mood/theme---soundscape'\n",
      " 'mood/theme---space' 'mood/theme---sport' 'mood/theme---summer'\n",
      " 'mood/theme---trailer' 'mood/theme---travel' 'mood/theme---upbeat'\n",
      " 'mood/theme---uplifting']\n"
     ]
    }
   ],
   "source": [
    "# print(mp3_dic[\"1171542\"]) 241.9\n",
    "# print(mp3_dic[\"1171546\"]) 144.1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "hdf5_files = []\n",
    "root_dir = \"../../dataset/jamendo/meta/tag_list.npy\"\n",
    "\n",
    "a = np.load(root_dir)\n",
    "print(a[127:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "root_dir = \"../../dataset/jamendo/out\"\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.midi'):\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            filepath2 = filepath.replace(\"out\",\"midi\")\n",
    "\n",
    "            # print(filepath)\n",
    "            # print(filepath2)\n",
    "            shutil.copyfile(filepath, filepath2)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "genre_path = '../../dataset/jamendo/meta/autotagging_genre.tsv'\n",
    "genre_dic = {}\n",
    "\n",
    "\n",
    "with open(genre_path, newline='') as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        headers = next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            tags = row[5:]\n",
    "            genre_dic[row[0]] = [tag.strip() for tag in tags if '---' in tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "genre_dic[\"track_0014393\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "fn_mert = '../../dataset/jamendo/mert/59/15159'\n",
    "latent_list_mert = []\n",
    "for filename in os.listdir(fn_mert):\n",
    "    file_path = os.path.join(fn_mert, filename)\n",
    "    if os.path.isfile(file_path) and filename.endswith('.npy'):\n",
    "        latent = np.load(file_path)\n",
    "        #latent = np.expand_dims(latent, axis=0)\n",
    "  \n",
    "        latent_list_mert.append(latent)\n",
    "        # shape : [1, 8192]\n",
    "\n",
    "\n",
    "latent_array_mert = np.vstack(latent_list_mert)  \n",
    "# Shape will be [num_segments, 8192]\n",
    "averaged_latent_mert = np.mean(latent_array_mert, axis=0)  # Shape will be [8192]\n",
    "print(averaged_latent_mert.shape)\n",
    "\n",
    "\n",
    "fn_m2l = '../../dataset/jamendo/music2latent/59/15159'\n",
    "latent_list_m2l = []\n",
    "for filename in os.listdir(fn_m2l):\n",
    "    file_path = os.path.join(fn_m2l, filename)\n",
    "    if os.path.isfile(file_path) and filename.endswith('.npy'):\n",
    "        latent = np.load(file_path)\n",
    "        #latent = np.expand_dims(latent, axis=0)\n",
    "        latent_list_m2l.append(latent)\n",
    "        # shape : [1, 8192]\n",
    "\n",
    "\n",
    "latent_array_m2l = np.vstack(latent_list_m2l)  \n",
    "\n",
    "# Shape will be [num_segments, 8192]\n",
    "averaged_latent_m2l = np.mean(latent_array_m2l, axis=0)  # Shape will be [8192]\n",
    "\n",
    "print(averaged_latent_m2l.shape)\n",
    "\n",
    "t1 = torch.from_numpy(averaged_latent_m2l)\n",
    "t2 = torch.from_numpy(averaged_latent_mert)\n",
    "t3 = torch.cat((t1, t2), dim=0)\n",
    "print(t3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from music21 import converter, key\n",
    "\n",
    "# Load the MIDI file\n",
    "midi_file = converter.parse('../data/948.midi')\n",
    "\n",
    "# Analyze the key\n",
    "key_signature = midi_file.analyze('key')\n",
    "\n",
    "# Print the detected key\n",
    "print(f\"Detected key: {key_signature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "directory = '../../dataset/jamendo/mp3'\n",
    "midi_directory = '../../repo/BTC-ISMIR19/out'\n",
    "\n",
    "missingfiles_path = \"../../repo/BTC-ISMIR19/missing\"\n",
    "\n",
    "missingfiles = []\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        root_midi = root.replace(\"mp3\",\"midi\")\n",
    "        if not os.path.exists(root_midi):\n",
    "            os.makedirs(root_midi)\n",
    "        file_path_midi_src = os.path.join(midi_directory, file.replace(\"mp3\", \"midi\"))        \n",
    "        file_path_midi_dst = os.path.join(root_midi, file.replace(\"mp3\", \"midi\") )\n",
    "\n",
    "        if not os.path.exists(file_path_midi_src):\n",
    "            missingfiles.append( file.replace(\"mp3\", \"midi\") )\n",
    "            shutil.copyfile(file_path, os.path.join(missingfiles_path, file))\n",
    "\n",
    "\n",
    "print(\"num of missing files:\", len(missingfiles))\n",
    "\n",
    "# for filename in os.listdir(fn):\n",
    "#     file_path = os.path.join(fn_mert, filename)\n",
    "#     if os.path.isfile(file_path) and filename.endswith('.npy'):\n",
    "#         latent = np.load(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def trim_audio_files(input_directory, output_directory, max_length_ms=3*60*1000):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "        print(f\"Created directory: {output_directory}\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp3'):\n",
    "                input_file_path = os.path.join(root, file)\n",
    "                output_file_path = os.path.join(output_directory, file)\n",
    "\n",
    "                # Load the MP3 file\n",
    "                audio = AudioSegment.from_mp3(input_file_path)\n",
    "                \n",
    "                # Check the length of the audio\n",
    "                if len(audio) > max_length_ms:\n",
    "                    # Trim the audio to the maximum length\n",
    "                    trimmed_audio = audio[:max_length_ms]\n",
    "                    print(f\"Trimming {file} to {max_length_ms/60000} minutes.\")\n",
    "                else:\n",
    "                    # No trimming needed\n",
    "                    trimmed_audio = audio\n",
    "                    print(f\"{file} is under {max_length_ms/60000} minutes, no trimming needed.\")\n",
    "                \n",
    "                # Save the trimmed audio to the output directory\n",
    "                trimmed_audio.export(output_file_path, format=\"mp3\")\n",
    "                print(f\"Saved trimmed file to: {output_file_path}\")\n",
    "\n",
    "# Specify the input and output directories\n",
    "input_directory = '../../repo/BTC-ISMIR19/missing'\n",
    "output_directory = '../../repo/BTC-ISMIR19/missing2'\n",
    "\n",
    "# Call the function to process the files\n",
    "trim_audio_files(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "directory = '../../dataset/jamendo/midi'\n",
    "chord_directory = '../../dataset/jamendo/midi'\n",
    "\n",
    "lab_directory = '../../repo/BTC-ISMIR19/out'\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        root_lab = root.replace(\"midi\",\"chord/lab\")\n",
    "        if not os.path.exists(root_lab):\n",
    "            os.makedirs(root_lab)\n",
    "        \n",
    "        lab_path_dst = os.path.join(root_lab, file.replace(\"midi\", \"lab\") )\n",
    "        lab_path_src = os.path.join(lab_directory, file.replace('midi', 'lab'))\n",
    "\n",
    "        shutil.copyfile(lab_path_src, lab_path_dst)\n",
    "        # root_midi = root.replace(\"mp3\",\"midi\")\n",
    "        # if not os.path.exists(root_midi):\n",
    "        #     os.makedirs(root_midi)\n",
    "        # file_path_midi_src = os.path.join(midi_directory, file.replace(\"mp3\", \"midi\"))        \n",
    "        # file_path_midi_dst = os.path.join(root_midi, file.replace(\"mp3\", \"midi\") )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia.standard as es\n",
    "\n",
    "def extract_emotion_relevant_features(audio_file, output_file=None):\n",
    "    # MusicExtractor with relevant feature groups\n",
    "    music_extractor = es.MusicExtractor(lowlevelStats=['mean', 'stdev'],\n",
    "                                        rhythmStats=['mean', 'stdev'],\n",
    "                                        tonalStats=['mean', 'stdev'])\n",
    "\n",
    "    features, _ = music_extractor(audio_file)\n",
    "    \n",
    "    if output_file:\n",
    "        features.save(output_file)\n",
    "        print(f\"Features saved to: {output_file}\")\n",
    "    else:\n",
    "        print(features)\n",
    "\n",
    "# Specify the path to your audio file\n",
    "audio_file = '/path/to/your/audio_file.mp3'\n",
    "\n",
    "# Specify the path to save the extracted features (optional)\n",
    "output_file = '/path/to/save/features.yaml'\n",
    "\n",
    "# Extract emotion-relevant features\n",
    "extract_emotion_relevant_features(audio_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Basic imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv, json\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import essentia.standard as ess\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "directory_model = '../../repo/AudioFeatureBasedPlaylists/Models'\n",
    "\n",
    "# All the filenames of the audio files in all the subfolders are saved into a .csv file.\n",
    "dir = os.path.join(path, 'MusAV/audio_chunks')\n",
    "data_file = 'filenames.csv'\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "if not Path(data_file).is_file or overwrite:\n",
    "  with open(data_file, 'w') as writer:\n",
    "    for subpath, _, files in os.walk(dir):\n",
    "      for name in files:\n",
    "        fileName = os.path.relpath(os.path.join(subpath,name), path)\n",
    "        line2write = fileName + '\\n'\n",
    "        writer.write(line2write)\n",
    "\n",
    "\n",
    "# All files are loaded from the .csv file into a list\n",
    "with open('filenames.csv', 'r') as fp:\n",
    "  fnReader = csv.reader(fp)\n",
    "  fileNames = list(fnReader)\n",
    "\n",
    "# Models initialization. The files of the pretrained models are loaded into the algorithms.\n",
    "\n",
    "# Voice/Instrumental model\n",
    "modelFile = os.path.join(directory_model, 'voice_instrumental-musicnn-msd-1.pb')\n",
    "modelVI = ess.TensorflowPredictMusiCNN(graphFilename=modelFile)\n",
    "\n",
    "# Arousal and valence\n",
    "modelFile = os.path.join(directory_model, 'msd-musicnn-1.pb')\n",
    "embeddings_model = ess.TensorflowPredictMusiCNN(graphFilename = modelFile, output = 'model/dense/BiasAdd')\n",
    "\n",
    "modelFile = os.path.join(directory_model, 'emomusic-musicnn-msd-2.pb')\n",
    "modelAV = ess.TensorflowPredict2D(graphFilename = modelFile, output = 'model/Identity')\n",
    "\n",
    "# Music Style\n",
    "modelFile = os.path.join(directory_model, 'discogs-effnet-bs64-1.pb')\n",
    "modelMS = ess.TensorflowPredictEffnetDiscogs(graphFilename=modelFile)\n",
    "\n",
    "jsonPath = os.path.join(directory_model, 'discogs-effnet-bs64-1.json')\n",
    "f = open(jsonPath)\n",
    "data = json.load(f)\n",
    "styles = data['classes']\n",
    "\n",
    "# Here there is an example analysis of a random audio file in the dataset.\n",
    "sample_file = random.choice(fileNames)[0]\n",
    "fs = 44100\n",
    "x = ess.MonoLoader(filename = sample_file, sampleRate = fs)()\n",
    "print(f'Sample_file = {sample_file}')\n",
    "plt.plot(x)\n",
    "ipd.Audio(x, rate=fs)\n",
    "\n",
    "# BPM Analysis\n",
    "bpm, _, _, _, _ = ess.RhythmExtractor2013()(x)\n",
    "# Danceability Analysis\n",
    "danceability, _ = ess.Danceability()(x)\n",
    "# Voice/Instrumental Analysis using a pretrained model\n",
    "activations = modelVI(x)\n",
    "meanVocInst = sum(activations)/len(activations)\n",
    "voice = meanVocInst[0]\n",
    "inst = meanVocInst[1]\n",
    "# Arousal and valence Analysis using a pretrained model on the Emomusic dataset\n",
    "embeddings = embeddings_model(x)\n",
    "arousalValence = modelAV(embeddings)\n",
    "meanArousalValence = sum(arousalValence)/len(arousalValence)\n",
    "arousal = meanArousalValence[0]\n",
    "valence = meanArousalValence[1]\n",
    "# Music Style Analysis using the Discogs Effnet pretrained model\n",
    "activations = modelMS(x)\n",
    "meanActivations = sum(activations)/len(activations)\n",
    "genreIndex = np.argmax(meanActivations)\n",
    "style = styles[genreIndex]\n",
    "\n",
    "print(f'Features:\\nBPM:\\t\\t{bpm}\\nDanceability:\\t{danceability}\\nVocal:\\t\\t{voice}\\nInstrumental:\\t{inst}\\nArousal:\\t{arousal}\\nValence:\\t{valence}\\nGenre:\\t\\t{style}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv, json\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import essentia.standard as ess\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory where your models are stored\n",
    "directory_model = '../../repo/AudioFeatureBasedPlaylists/Models'\n",
    "\n",
    "# Specify the path to your input audio file or directory containing audio files\n",
    "# Option 1: Single file\n",
    "input_audio_file = '../data/7400.mp3'  # Example: '/home/user/music/audio_file.mp3'\n",
    "\n",
    "# Option 2: Directory containing multiple audio files\n",
    "# input_audio_dir = '/path/to/your/audio_directory'  # Example: '/home/user/music/audio_chunks'\n",
    "\n",
    "# Initialize a list to hold the file paths\n",
    "file_paths = []\n",
    "\n",
    "# If you want to analyze a single file, add it to the list\n",
    "if os.path.isfile(input_audio_file):\n",
    "    file_paths.append(input_audio_file)\n",
    "\n",
    "# If you want to analyze all files in a directory, iterate through the directory and add the files to the list\n",
    "# if os.path.isdir(input_audio_dir):\n",
    "#     for subpath, _, files in os.walk(input_audio_dir):\n",
    "#         for name in files:\n",
    "#             if name.endswith('.mp3') or name.endswith('.wav'):  # Add conditions for supported formats\n",
    "#                 file_paths.append(os.path.join(subpath, name))\n",
    "\n",
    "# Load your pre-trained models\n",
    "# Voice/Instrumental model\n",
    "modelFile = os.path.join(directory_model, 'voice_instrumental-musicnn-msd-1.pb')\n",
    "modelVI = ess.TensorflowPredictMusiCNN(graphFilename=modelFile)\n",
    "\n",
    "# Arousal and valence model\n",
    "modelFile = os.path.join(directory_model, 'msd-musicnn-1.pb')\n",
    "embeddings_model = ess.TensorflowPredictMusiCNN(graphFilename = modelFile, output = 'model/dense/BiasAdd')\n",
    "\n",
    "modelFile = os.path.join(directory_model, 'emomusic-musicnn-msd-2.pb')\n",
    "modelAV = ess.TensorflowPredict2D(graphFilename = modelFile, output = 'model/Identity')\n",
    "\n",
    "# Music Style model\n",
    "modelFile = os.path.join(directory_model, 'discogs-effnet-bs64-1.pb')\n",
    "modelMS = ess.TensorflowPredictEffnetDiscogs(graphFilename=modelFile)\n",
    "\n",
    "# Load the styles associated with the Music Style model\n",
    "jsonPath = os.path.join(directory_model, 'discogs-effnet-bs64-1.json')\n",
    "with open(jsonPath) as f:\n",
    "    data = json.load(f)\n",
    "    styles = data['classes']\n",
    "\n",
    "# Process each file in the list\n",
    "for sample_file in file_paths:\n",
    "    fs = 44100\n",
    "    x = ess.MonoLoader(filename=sample_file, sampleRate=fs)()\n",
    "\n",
    "    # print(f'Analyzing file: {sample_file}')\n",
    "    # plt.plot(x)\n",
    "    # ipd.Audio(x, rate=fs)\n",
    "\n",
    "    # BPM Analysis\n",
    "    bpm, _, _, _, _ = ess.RhythmExtractor2013()(x)\n",
    "    \n",
    "    # Danceability Analysis\n",
    "    danceability, _ = ess.Danceability()(x)\n",
    "    \n",
    "    # Voice/Instrumental Analysis using a pretrained model\n",
    "    activations = modelVI(x)\n",
    "    meanVocInst = sum(activations) / len(activations)\n",
    "    voice = meanVocInst[0]\n",
    "    inst = meanVocInst[1]\n",
    "    \n",
    "    # Arousal and valence Analysis using a pretrained model on the Emomusic dataset\n",
    "    embeddings = embeddings_model(x)\n",
    "    arousalValence = modelAV(embeddings)\n",
    "    meanArousalValence = sum(arousalValence) / len(arousalValence)\n",
    "    arousal = meanArousalValence[0]\n",
    "    valence = meanArousalValence[1]\n",
    "    \n",
    "    # Music Style Analysis using the Discogs Effnet pretrained model\n",
    "    activations = modelMS(x)\n",
    "    meanActivations = sum(activations) / len(activations)\n",
    "    genreIndex = np.argmax(meanActivations)\n",
    "    style = styles[genreIndex]\n",
    "\n",
    "    # Print the extracted features\n",
    "    print(f'Features for {sample_file}:\\n'\n",
    "          f'BPM:\\t\\t{bpm}\\n'\n",
    "          f'Danceability:\\t{danceability}\\n'\n",
    "          f'Vocal:\\t\\t{voice}\\n'\n",
    "          f'Instrumental:\\t{inst}\\n'\n",
    "          f'Arousal:\\t{arousal}\\n'\n",
    "          f'Valence:\\t{valence}\\n'\n",
    "          f'Genre:\\t\\t{style}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from music21 import converter, key\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "directory = '../../dataset/jamendo/midi'\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        key_path = file_path[0:-4] + \"lab\"\n",
    "        key_path = key_path.replace(\"midi\", \"key\")\n",
    "\n",
    "        print(file_path)\n",
    "        \n",
    "        print(key_path)\n",
    "        assert(False)\n",
    "\n",
    "\n",
    "        midi_file = converter.parse('../data/948.midi')\n",
    "        key_signature = midi_file.analyze('key')\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Load the MIDI file\n",
    "midi_file = converter.parse('../data/948.midi')\n",
    "\n",
    "# Analyze the key\n",
    "key_signature = midi_file.analyze('key')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the detected key\n",
    "print(f\"Detected key: {key_signature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = '../../dataset/jamendo/mert_30s_all'\n",
    "items = os.listdir(directory)\n",
    "\n",
    "    # Count how many of those items are directories\n",
    "subdirectories = [item for item in items if os.path.isdir(os.path.join(directory, item))]\n",
    "print(len(subdirectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../dataset/jamendo/mert_30s_all/00/7400/segment_0.npy'\n",
    "import numpy as np\n",
    "a\n",
    "n = np.load(path)\n",
    "print(n.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Initialize the feature dimensions for each encoder\n",
    "ENCODER = \"M2L\"\n",
    "\n",
    "feature_dim_dict = {\n",
    "    \"MERT\": 768,\n",
    "    \"M2L\": 8192,\n",
    "    \"LIBROSA\": 51\n",
    "}\n",
    "\n",
    "# Split the ENCODER string by the delimiter \"-\" to get the individual encoders\n",
    "encoders = ENCODER.split(\"-\")\n",
    "\n",
    "# Calculate the total input dimension by summing the dimensions of the selected encoders\n",
    "inputdim = sum(feature_dim_dict[encoder] for encoder in encoders)\n",
    "print(inputdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "song_id = 3135556\n",
    "url = f\"https://api.deezer.com/track/{song_id}\"\n",
    "response = requests.get(url)\n",
    "track_info = response.json()\n",
    "\n",
    "# Get the preview URL\n",
    "preview_url = track_info['preview']\n",
    "\n",
    "# Download the audio preview\n",
    "audio_response = requests.get(preview_url)\n",
    "\n",
    "# Save the audio file locally\n",
    "with open('preview.mp3', 'wb') as f:\n",
    "    f.write(audio_response.content)\n",
    "\n",
    "print(\"Audio preview downloaded as preview.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "p = \"../script/dmdd_train\"\n",
    "p2 = \"../script/dmdd_val\"\n",
    "p3 = \"../script/dmdd_test\"\n",
    "\n",
    "l = os.listdir(p)\n",
    "l2 = os.listdir(p2)\n",
    "l3 = os.listdir(p3)\n",
    "\n",
    "\n",
    "print(len(l))\n",
    "print(len(l2))\n",
    "print(len(l3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7534+2565+2190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "fn = '../../dataset/jamendo/splits/split-0/moodtheme_train_dict.pickle'\n",
    "with open(fn, 'rb') as pf:\n",
    "    dictionary = pickle.load(pf)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"lsof /dev/nvidia* | awk '{print $2}' | xargs -I {} kill {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3019650/915614166.py:14: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=frequency, y=datasets, palette='plasma')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dataset frequency data\n",
    "datasets = ['Self-built', 'DEAM', 'MTG-Jamendo', 'PMEmo', 'Solymani et al.s dataset',\n",
    "            'Soundtrack', 'Last.fm', 'Bi-Modal', \n",
    "            'Midlevel', 'EMOPIA', 'VGMIDI', 'DMDD', \n",
    "             'Musical Excerpts', '4Q audio', 'FMA', 'RAVDESS']\n",
    "\n",
    "frequency = [11, 8, 6, 5, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=frequency, y=datasets, palette='plasma')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Dataset')\n",
    "plt.title('Frequency of Datasets in Music Emotion Recognition Models since 2020')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import Audio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spotipy\n",
    "\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy import SpotifyException\n",
    "\n",
    "\n",
    "\n",
    "# lastfm_url\ttrack\tartist\tseeds\tnumber_of_emotion_tags\tvalence_tags\tarousal_tags\tdominance_tags\tmbid\tspotify_id\tgenre\n",
    "# https://www.last.fm/music/eminem/_/%2527till%2bi%2bcollapse\t'Till I Collapse\tEminem\t['aggressive']\t6\t4.55\t5.273125000000000\t5.690625\tcab93def-26c5-4fb0-bedd-26ec4c1619e1\t4xkOaSrkexMciUUogZKVTS\trap\n",
    "# https://www.last.fm/music/metallica/_/st.%2banger\tSt. Anger\tMetallica\t['aggressive']\t8\t3.71\t5.833000000000000\t5.427250000000000\t727a2529-7ee8-4860-aef6-7959884895cb\t3fOc9x06lKJBhz435mInlH\tmetal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned train.csv: 11267 rows to 7534 rows. Saved to ../../dataset/dmdd/meta/cleaned_train.csv\n",
      "Cleaned test.csv: 3514 rows to 2190 rows. Saved to ../../dataset/dmdd/meta/cleaned_test.csv\n",
      "Cleaned val.csv: 3863 rows to 2565 rows. Saved to ../../dataset/dmdd/meta/cleaned_val.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base paths to the directories\n",
    "base_meta_dir = \"../../dataset/dmdd/meta\"  # Path to the directory containing CSV files\n",
    "base_mp3_dir = \"../../dataset/dmdd/mp3\"    # Path to the directory containing mp3 subdirectories\n",
    "\n",
    "# List of CSV files and corresponding subdirectories in the mp3 folder\n",
    "csv_files = {\n",
    "    \"train.csv\": \"dmdd_train\",\n",
    "    \"test.csv\": \"dmdd_test\",\n",
    "    \"val.csv\": \"dmdd_val\"\n",
    "}\n",
    "\n",
    "# Iterate through each CSV file and its corresponding mp3 subdirectory\n",
    "for csv_file, mp3_subdir in csv_files.items():\n",
    "    # Full path to the CSV file\n",
    "    csv_path = os.path.join(base_meta_dir, csv_file)\n",
    "    \n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Full path to the mp3 subdirectory\n",
    "    mp3_subdir_path = os.path.join(base_mp3_dir, mp3_subdir)\n",
    "    \n",
    "    # Check if mp3 file exists for each dzr_sng_id in the CSV\n",
    "    df_cleaned = df[df[\"dzr_sng_id\"].apply(lambda x: os.path.exists(os.path.join(mp3_subdir_path, f\"{x}.mp3\")))]\n",
    "    \n",
    "    # Save the cleaned dataframe back to CSV (you can change the path if you want to save it elsewhere)\n",
    "    output_path = os.path.join(base_meta_dir, f\"cleaned_{csv_file}\")\n",
    "    df_cleaned.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Cleaned {csv_file}: {len(df)} rows to {len(df_cleaned)} rows. Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development count: 619\n",
      "Evaluation count: 125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = '../data/songs_info.csv'  # replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Strip any leading or trailing whitespaces from the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Count the occurrences of 'development' and 'evaluation' in the 'Mediaeval 2013 set' column\n",
    "development_count = df[df['Mediaeval 2013 set'].str.strip() == 'development'].shape[0]\n",
    "evaluation_count = df[df['Mediaeval 2013 set'].str.strip() == 'evaluation'].shape[0]\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Development count: {development_count}\")\n",
    "print(f\"Evaluation count: {evaluation_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song IDs saved to train_song_ids.txt, val_song_ids.txt, and test_song_ids.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = '../data/songs_info.csv'  # replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Strip any leading or trailing whitespaces from the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Filter development and evaluation sets\n",
    "development_df = df[df['Mediaeval 2013 set'].str.strip() == 'development']\n",
    "evaluation_df = df[df['Mediaeval 2013 set'].str.strip() == 'evaluation']\n",
    "\n",
    "# Split development set into training and validation sets (80% train, 20% validation)\n",
    "train_df, val_df = train_test_split(development_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save only 'song_id' for each set to text files\n",
    "train_df['song_id'].to_csv('train_song_ids.txt', index=False, header=False)\n",
    "val_df['song_id'].to_csv('val_song_ids.txt', index=False, header=False)\n",
    "evaluation_df['song_id'].to_csv('test_song_ids.txt', index=False, header=False)\n",
    "\n",
    "print(\"Song IDs saved to train_song_ids.txt, val_song_ids.txt, and test_song_ids.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song IDs saved to train_song_ids.txt, val_song_ids.txt, and test_song_ids.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the second CSV file into a pandas DataFrame\n",
    "file_path = '../data/static_all.csv'  # replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Strip any leading or trailing whitespaces from the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "# First, split the data into 80% train+val and 20% test\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now split the train+val set into 80% train and 20% validation\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save only 'musicId' for each set to text files\n",
    "train_df['song_id'].to_csv('train.txt', index=False, header=False)\n",
    "val_df['song_id'].to_csv('val.txt', index=False, header=False)\n",
    "test_df['song_id'].to_csv('test.txt', index=False, header=False)\n",
    "\n",
    "print(\"Song IDs saved to train_song_ids.txt, val_song_ids.txt, and test_song_ids.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV file saved as 'filtered_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = '../data/2.csv'  # replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Strip any leading or trailing whitespaces from the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Select only the required columns\n",
    "filtered_df = df[['song_id', 'valence_mean', 'valence_std', 'arousal_mean', 'arousal_std']]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_df.to_csv('filtered_data.csv', index=False)\n",
    "\n",
    "print(\"Filtered CSV file saved as 'filtered_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to: ../../dataset/pmemo/meta/combined_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "annotations_mean = pd.read_csv(\"../../dataset/pmemo/meta/static_annotations.csv\")\n",
    "annotations_std = pd.read_csv(\"../../dataset/pmemo/meta/static_annotations_std.csv\")\n",
    "\n",
    "# Merge the two DataFrames on the 'musicId' column\n",
    "combined_annotations = pd.merge(annotations_mean, annotations_std, on=\"musicId\", how=\"inner\")\n",
    "\n",
    "# Rename the columns as specified\n",
    "combined_annotations.rename(columns={\n",
    "    'musicId': 'song_id',\n",
    "    'Valence(mean)': 'valence_mean',\n",
    "    'Arousal(mean)': 'arousal_mean',\n",
    "    'Valence(std)': 'valence_std',\n",
    "    'Arousal(std)': 'arousal_std'\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorder the columns\n",
    "combined_annotations = combined_annotations[['song_id', 'valence_mean', 'valence_std', 'arousal_mean', 'arousal_std']]\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "output_file = \"../../dataset/pmemo/meta/combined_annotations.csv\"\n",
    "combined_annotations.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Combined CSV saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordered CSV file saved as 'reordered_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "file_path = '../../dataset/emomusic/meta/static_annotations.csv'  # replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Strip any leading or trailing whitespaces from the column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Rename the columns to match your desired format\n",
    "df.rename(columns={\n",
    "    'mean_valence': 'valence_mean', \n",
    "    'std_valence': 'valence_std',\n",
    "    'mean_arousal': 'arousal_mean', \n",
    "    'std_arousal': 'arousal_std'\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorder the columns\n",
    "df = df[['song_id', 'valence_mean', 'valence_std', 'arousal_mean', 'arousal_std']]\n",
    "\n",
    "# Save the reordered DataFrame to a new CSV file\n",
    "df.to_csv('../../dataset/emomusic/meta/static_annotations.csv', index=False)\n",
    "\n",
    "print(\"Reordered CSV file saved as 'reordered_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = \"../../dataset/deam/meta/static_annotations.csv\"  # Replace with your actual CSV file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Extract the song_id column from the CSV\n",
    "csv_song_ids = set(df['song_id'])\n",
    "\n",
    "# Load song IDs from text files\n",
    "def load_song_ids_from_txt(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return set(int(line.strip()) for line in file.readlines())\n",
    "\n",
    "# File paths for test, val, and train text files\n",
    "test_file = \"../../dataset/deam/meta/split/test.txt\"  # Replace with your actual file paths\n",
    "val_file = \"../../dataset/deam/meta/split/validation.txt\"\n",
    "train_file = \"../../dataset/deam/meta/split/train.txt\"\n",
    "\n",
    "# Load song IDs from all text files\n",
    "test_song_ids = load_song_ids_from_txt(test_file)\n",
    "val_song_ids = load_song_ids_from_txt(val_file)\n",
    "train_song_ids = load_song_ids_from_txt(train_file)\n",
    "\n",
    "# Combine all song IDs from text files\n",
    "all_txt_song_ids = test_song_ids.union(val_song_ids, train_song_ids)\n",
    "\n",
    "# Split into train, test, and validation sets (e.g., 70% train, 15% test, 15% validation)\n",
    "train_ids, test_val_ids = train_test_split(list(all_txt_song_ids), test_size=0.3, random_state=42)\n",
    "test_ids, val_ids = train_test_split(test_val_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "# Function to save song IDs to a text file\n",
    "def save_song_ids_to_file(song_ids, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for song_id in song_ids:\n",
    "            f.write(f\"{song_id}\\n\")\n",
    "\n",
    "# Save train, test, and validation sets to text files\n",
    "save_song_ids_to_file(train_ids, \"dtrain.txt\")\n",
    "save_song_ids_to_file(test_ids, \"dtest.txt\")\n",
    "save_song_ids_to_file(val_ids, \"dvalidation.txt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# available_song_ids= all_txt_song_ids-missing_song_ids\n",
    "\n",
    "# # Split into train, test, and validation sets (e.g., 70% train, 15% test, 15% validation)\n",
    "# train_ids, test_val_ids = train_test_split(list(available_song_ids), test_size=0.3, random_state=42)\n",
    "# test_ids, val_ids = train_test_split(test_val_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Function to save song IDs to a text file\n",
    "# def save_song_ids_to_file(song_ids, file_name):\n",
    "#     with open(file_name, 'w') as f:\n",
    "#         for song_id in song_ids:\n",
    "#             f.write(f\"{song_id}\\n\")\n",
    "\n",
    "# # Save train, test, and validation sets to text files\n",
    "# save_song_ids_to_file(train_ids, \"ptrain.txt\")\n",
    "# save_song_ids_to_file(test_ids, \"ptest.txt\")\n",
    "# save_song_ids_to_file(val_ids, \"pval.txt\")\n",
    "\n",
    "# print(\"Song IDs have been split and saved to text files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "Sum of all values: 1.797668107347472\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = np.load (\"../data/probas_train.npy\")\n",
    "\n",
    "print(len(n))\n",
    "total_sum = np.sum(n)\n",
    "\n",
    "# Print the result\n",
    "print(\"Sum of all values:\", total_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chord Vocabulary (from JSON): {'N': 0, 'C': 1, 'C:dim': 2, 'C:sus4': 3, 'C:min7': 4, 'C:min': 5, 'C:sus2': 6, 'C:aug': 7, 'C:dim7': 8, 'C:maj6': 9, 'C:hdim7': 10, 'C:7': 11, 'C:min6': 12, 'C:maj7': 13, 'C#': 14, 'C#:dim': 15, 'C#:sus4': 16, 'C#:min7': 17, 'C#:min': 18, 'C#:sus2': 19, 'C#:aug': 20, 'C#:dim7': 21, 'C#:maj6': 22, 'C#:hdim7': 23, 'C#:7': 24, 'C#:min6': 25, 'C#:maj7': 26, 'D': 27, 'D:dim': 28, 'D:sus4': 29, 'D:min7': 30, 'D:min': 31, 'D:sus2': 32, 'D:aug': 33, 'D:dim7': 34, 'D:maj6': 35, 'D:hdim7': 36, 'D:7': 37, 'D:min6': 38, 'D:maj7': 39, 'D#': 40, 'D#:dim': 41, 'D#:sus4': 42, 'D#:min7': 43, 'D#:min': 44, 'D#:sus2': 45, 'D#:aug': 46, 'D#:dim7': 47, 'D#:maj6': 48, 'D#:hdim7': 49, 'D#:7': 50, 'D#:min6': 51, 'D#:maj7': 52, 'E': 53, 'E:dim': 54, 'E:sus4': 55, 'E:min7': 56, 'E:min': 57, 'E:sus2': 58, 'E:aug': 59, 'E:dim7': 60, 'E:maj6': 61, 'E:hdim7': 62, 'E:7': 63, 'E:min6': 64, 'E:maj7': 65, 'F': 66, 'F:dim': 67, 'F:sus4': 68, 'F:min7': 69, 'F:min': 70, 'F:sus2': 71, 'F:aug': 72, 'F:dim7': 73, 'F:maj6': 74, 'F:hdim7': 75, 'F:7': 76, 'F:min6': 77, 'F:maj7': 78, 'F#': 79, 'F#:dim': 80, 'F#:sus4': 81, 'F#:min7': 82, 'F#:min': 83, 'F#:sus2': 84, 'F#:aug': 85, 'F#:dim7': 86, 'F#:maj6': 87, 'F#:hdim7': 88, 'F#:7': 89, 'F#:min6': 90, 'F#:maj7': 91, 'G': 92, 'G:dim': 93, 'G:sus4': 94, 'G:min7': 95, 'G:min': 96, 'G:sus2': 97, 'G:aug': 98, 'G:dim7': 99, 'G:maj6': 100, 'G:hdim7': 101, 'G:7': 102, 'G:min6': 103, 'G:maj7': 104, 'G#': 105, 'G#:dim': 106, 'G#:sus4': 107, 'G#:min7': 108, 'G#:min': 109, 'G#:sus2': 110, 'G#:aug': 111, 'G#:dim7': 112, 'G#:maj6': 113, 'G#:hdim7': 114, 'G#:7': 115, 'G#:min6': 116, 'G#:maj7': 117, 'A': 118, 'A:dim': 119, 'A:sus4': 120, 'A:min7': 121, 'A:min': 122, 'A:sus2': 123, 'A:aug': 124, 'A:dim7': 125, 'A:maj6': 126, 'A:hdim7': 127, 'A:7': 128, 'A:min6': 129, 'A:maj7': 130, 'A#': 131, 'A#:dim': 132, 'A#:sus4': 133, 'A#:min7': 134, 'A#:min': 135, 'A#:sus2': 136, 'A#:aug': 137, 'A#:dim7': 138, 'A#:maj6': 139, 'A#:hdim7': 140, 'A#:7': 141, 'A#:min6': 142, 'A#:maj7': 143, 'B': 144, 'B:dim': 145, 'B:sus4': 146, 'B:min7': 147, 'B:min': 148, 'B:sus2': 149, 'B:aug': 150, 'B:dim7': 151, 'B:maj6': 152, 'B:hdim7': 153, 'B:7': 154, 'B:min6': 155, 'B:maj7': 156}\n",
      "Encoded Chords: [  0 122   1  70   0 144 148 118   1  66 144  66  53 118 122 118 122   1\n",
      "  66 148 118   1  66 144 154 146 154 118 122   1  66 147 118   1  66 154\n",
      " 146 154  92 118   1  66 144  66  53 118   0]\n",
      "Durations: [10.     1.944  4.167  3.704  0.185  1.574  2.407  3.982  4.074  3.889\n",
      "  4.074  3.981  3.982  0.926  1.018  0.093  1.944  4.075  3.981  3.889\n",
      "  4.074  4.074  3.889  0.185  0.093  1.296  2.5    1.019  2.962  4.075\n",
      "  3.888  3.982  4.074  4.074  3.889  0.093  1.481  0.463  1.944  3.982\n",
      "  4.074  3.981  4.075  3.888  3.982  8.611  1.482]\n",
      "Chords Tensor: tensor([  0, 122,   1,  70,   0, 144, 148, 118,   1,  66, 144,  66,  53, 118,\n",
      "        122, 118, 122,   1,  66, 148, 118,   1,  66, 144, 154, 146, 154, 118,\n",
      "        122,   1,  66, 147, 118,   1,  66, 154, 146, 154,  92, 118,   1,  66,\n",
      "        144,  66,  53, 118,   0])\n",
      "Durations Tensor: tensor([10.0000,  1.9440,  4.1670,  3.7040,  0.1850,  1.5740,  2.4070,  3.9820,\n",
      "         4.0740,  3.8890,  4.0740,  3.9810,  3.9820,  0.9260,  1.0180,  0.0930,\n",
      "         1.9440,  4.0750,  3.9810,  3.8890,  4.0740,  4.0740,  3.8890,  0.1850,\n",
      "         0.0930,  1.2960,  2.5000,  1.0190,  2.9620,  4.0750,  3.8880,  3.9820,\n",
      "         4.0740,  4.0740,  3.8890,  0.0930,  1.4810,  0.4630,  1.9440,  3.9820,\n",
      "         4.0740,  3.9810,  4.0750,  3.8880,  3.9820,  8.6110,  1.4820])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 1: Load JSON mappings\n",
    "def load_chord_mappings(chord_json_path, chord_invert_json_path):\n",
    "    with open(chord_json_path, 'r') as f:\n",
    "        chord_to_idx = json.load(f)\n",
    "    with open(chord_invert_json_path, 'r') as f:\n",
    "        idx_to_chord = json.load(f)\n",
    "        idx_to_chord = {int(k): v for k, v in idx_to_chord.items()}  # Ensure keys are ints\n",
    "    return chord_to_idx, idx_to_chord\n",
    "\n",
    "# Step 2: Load the `.lab` file\n",
    "def load_chord_file(filepath):\n",
    "    chords = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            start, end, chord = line.strip().split()\n",
    "            chords.append((float(start), float(end), chord))\n",
    "    return chords\n",
    "\n",
    "# Step 3: Encode chords using `chord.json`\n",
    "def encode_chords_with_json(chords, chord_to_idx):\n",
    "    encoded = []\n",
    "    durations = []\n",
    "    for start, end, chord in chords:\n",
    "        if chord in chord_to_idx:\n",
    "            encoded.append(chord_to_idx[chord])\n",
    "        else:\n",
    "            raise ValueError(f\"Chord {chord} not found in chord.json!\")\n",
    "        durations.append(end - start)  # Compute duration\n",
    "    return np.array(encoded), np.array(durations)\n",
    "\n",
    "# Step 4: Convert to PyTorch tensors\n",
    "def prepare_chord_tensors(encoded_chords, durations):\n",
    "    chords_tensor = torch.tensor(encoded_chords, dtype=torch.long)  # For embedding\n",
    "    durations_tensor = torch.tensor(durations, dtype=torch.float32)  # Optional\n",
    "    return chords_tensor, durations_tensor\n",
    "\n",
    "# Example Usage\n",
    "chord_json_path = \"../data/chord.json\"\n",
    "chord_invert_json_path = \"../data/chord_inv.json\"\n",
    "lab_file_path = \"../data/7400.lab\"\n",
    "\n",
    "# Load mappings\n",
    "chord_to_idx, idx_to_chord = load_chord_mappings(chord_json_path, chord_invert_json_path)\n",
    "\n",
    "# Load and encode chords\n",
    "chords = load_chord_file(lab_file_path)\n",
    "encoded_chords, durations = encode_chords_with_json(chords, chord_to_idx)\n",
    "chords_tensor, durations_tensor = prepare_chord_tensors(encoded_chords, durations)\n",
    "\n",
    "print(\"Chord Vocabulary (from JSON):\", chord_to_idx)\n",
    "print(\"Encoded Chords:\", encoded_chords)\n",
    "print(\"Durations:\", durations)\n",
    "print(\"Chords Tensor:\", chords_tensor)\n",
    "print(\"Durations Tensor:\", durations_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mp3_files = []\n",
    "mp3_dic={}\n",
    "root_dir = \"../../dataset/jamendo/key\"\n",
    "d= set()\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.lab'):\n",
    "                with open( os.path.join(dirpath, filename), 'r') as file:\n",
    "                    for line in file:\n",
    "                        k = line.strip()\n",
    "                        d.add(k)\n",
    "                        break\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Index: 4\n",
      "Key One-Hot Encoding: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the key signature vocabulary\n",
    "key_signatures = [\n",
    "    \"A major\", \"A- major\", \"B major\", \"B- major\", \"C major\", \"C# major\", \"D major\", \"E major\", \n",
    "    \"E- major\", \"F major\", \"F# major\", \"G major\", \"None\", \"a minor\", \"b minor\", \"b- minor\", \n",
    "    \"c minor\", \"c# minor\", \"d minor\", \"e minor\", \"e- minor\", \"f minor\", \"f# minor\", \n",
    "    \"g minor\", \"g# minor\"\n",
    "]\n",
    "key_to_idx = {key: idx for idx, key in enumerate(key_signatures)}\n",
    "idx_to_key = {idx: key for key, idx in key_to_idx.items()}\n",
    "\n",
    "# Step 2: Encode a key signature\n",
    "def encode_key_signature(key, key_to_idx):\n",
    "    if key in key_to_idx:\n",
    "        return key_to_idx[key]\n",
    "    else:\n",
    "        raise ValueError(f\"Key signature '{key}' not found in key signature vocabulary!\")\n",
    "\n",
    "# Step 3: Optionally, one-hot encode the key signature\n",
    "def one_hot_encode_key_signature(key_idx, num_keys=len(key_signatures)):\n",
    "    one_hot = [0] * num_keys\n",
    "    one_hot[key_idx] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Example Usage\n",
    "song_key = \"C major\"  # Replace with the actual key signature of the song\n",
    "key_index = encode_key_signature(song_key, key_to_idx)\n",
    "key_one_hot = one_hot_encode_key_signature(key_index)\n",
    "\n",
    "print(\"Key Index:\", key_index)\n",
    "print(\"Key One-Hot Encoding:\", key_one_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Embedding: tensor([[-1.4218, -1.3981, -0.6014, -0.2019, -0.6691, -0.2530, -0.1684, -1.1054,\n",
      "         -1.0970, -1.1959, -1.7183, -0.4997, -0.9512,  0.0457, -0.3897, -0.3003]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Combine chord embeddings and key signature\n",
    "chords_tensor = torch.tensor([1, 2, 3])  # Example chord indices\n",
    "key_tensor = torch.tensor(key_index, dtype=torch.long)  # Key index\n",
    "\n",
    "# Optionally, embed the key signature\n",
    "key_embedding_layer = torch.nn.Embedding(len(key_signatures), 16)  # Example embedding size: 16\n",
    "key_embedding = key_embedding_layer(key_tensor.unsqueeze(0))\n",
    "\n",
    "print(\"Key Embedding:\", key_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "II\n"
     ]
    }
   ],
   "source": [
    "import chordparser\n",
    "\n",
    "cp = chordparser.Parser()\n",
    "new_chord = cp.create_chord(\"A#\")\n",
    "key = cp.create_scale(\"G#\", \"major\")\n",
    "roman = cp.to_roman(new_chord, key)\n",
    "print(str(roman))\n",
    "\n",
    "\n",
    "\n",
    "# >>> new_chord.notes\n",
    "# (E note, C note, F note, G note, B note)\n",
    "\n",
    "# >>> new_chord.transpose_simple(6)\n",
    "# F7add4/A chord\n",
    "# >>> new_chord.notes\n",
    "# (A note, F note, B note, C note, E note)\n",
    "\n",
    "# >>> e_scale = cp.create_scale(\"E\", \"major\")\n",
    "# >>> cp.to_roman(new_chord, e_scale)\n",
    "# II65 roman chord\n",
    "\n",
    "# >>> e_fifth = cp.create_diatonic(e_scale, 5)\n",
    "# >>> e_fifth\n",
    "# B chord\n",
    "# >>> cp.analyse_secondary(new_chord, e_fifth, e_scale)\n",
    "# \"V65/V\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action\n",
      "adventure\n",
      "advertising\n",
      "background\n",
      "ballad\n",
      "calm\n",
      "children\n",
      "christmas\n",
      "commercial\n",
      "cool\n",
      "corporate\n",
      "dark\n",
      "deep\n",
      "documentary\n",
      "drama\n",
      "dramatic\n",
      "dream\n",
      "emotional\n",
      "energetic\n",
      "epic\n",
      "fast\n",
      "film\n",
      "fun\n",
      "funny\n",
      "game\n",
      "groovy\n",
      "happy\n",
      "heavy\n",
      "holiday\n",
      "hopeful\n",
      "inspiring\n",
      "love\n",
      "meditative\n",
      "melancholic\n",
      "melodic\n",
      "motivational\n",
      "movie\n",
      "nature\n",
      "party\n",
      "positive\n",
      "powerful\n",
      "relaxing\n",
      "retro\n",
      "romantic\n",
      "sad\n",
      "sexy\n",
      "slow\n",
      "soft\n",
      "soundscape\n",
      "space\n",
      "sport\n",
      "summer\n",
      "trailer\n",
      "travel\n",
      "upbeat\n",
      "uplifting\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = np.load ( \"../data/tag_list.npy\")\n",
    "\n",
    "with open(\"moodtaglist.txt\", \"w\") as f:\n",
    "    for tag in n:\n",
    "        if \"mood/theme\" in tag:\n",
    "            print(tag[13:])\n",
    "            f.write(tag[13:] + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence and Arousal scores assigned and saved to moodtag_valence_arousal_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "mood_tag_file = \"../data/moodtaglist.txt\"\n",
    "valence_arousal_file = \"../data/work2vad.csv\"  # Replace with your actual CSV file path\n",
    "\n",
    "output_file = \"moodtag_valence_arousal_scores.csv\"\n",
    "\n",
    "# Load mood tags\n",
    "with open(mood_tag_file, \"r\") as file:\n",
    "    mood_tags = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Load Valence and Arousal data\n",
    "va_data = pd.read_csv(valence_arousal_file)\n",
    "\n",
    "# Ensure the column names match your data file\n",
    "# Assuming \"Word\", \"V.Mean.Sum\", and \"A.Mean.Sum\" are column headers in the CSV\n",
    "va_data = va_data[[\"Word\", \"V.Mean.Sum\", \"A.Mean.Sum\"]]\n",
    "va_data.columns = [\"Word\", \"Valence\", \"Arousal\"]  # Renaming for clarity\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Assign Valence and Arousal scores to each mood tag\n",
    "for tag in mood_tags:\n",
    "    match = va_data[va_data[\"Word\"].str.lower() == tag.lower()]  # Match case-insensitively\n",
    "    if not match.empty:\n",
    "        valence = match.iloc[0][\"Valence\"]\n",
    "        arousal = match.iloc[0][\"Arousal\"]\n",
    "        results.append({\"MoodTag\": tag, \"Valence\": valence, \"Arousal\": arousal})\n",
    "    else:\n",
    "        results.append({\"MoodTag\": tag, \"Valence\": None, \"Arousal\": None})  # No match found\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Valence and Arousal scores assigned and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V.Mean.Sum - Min: 1.26, Max: 8.53\n",
      "A.Mean.Sum - Min: 1.6, Max: 7.79\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"../data/work2vad.csv\")\n",
    "\n",
    "\n",
    "# Compute min and max for V.Mean.Sum and A.Mean.Sum\n",
    "v_mean_min = data[\"V.Mean.Sum\"].min()\n",
    "v_mean_max = data[\"V.Mean.Sum\"].max()\n",
    "\n",
    "a_mean_min = data[\"A.Mean.Sum\"].min()\n",
    "a_mean_max = data[\"A.Mean.Sum\"].max()\n",
    "\n",
    "# Print the results\n",
    "print(f\"V.Mean.Sum - Min: {v_mean_min}, Max: {v_mean_max}\")\n",
    "print(f\"A.Mean.Sum - Min: {a_mean_min}, Max: {a_mean_max}\")\n",
    "\n",
    "# Load pre-trained SentenceTransformer model\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and effective for word embeddings\n",
    "\n",
    "# # Separate missing and available data\n",
    "# missing_data = data[data.isnull().any(axis=1)].copy()\n",
    "# available_data = data.dropna().copy()\n",
    "\n",
    "# # Generate embeddings for the words\n",
    "# available_embeddings = model.encode(available_data[\"MoodTag\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# # Assign scores to missing values\n",
    "# for idx, row in missing_data.iterrows():\n",
    "#     # Embed the missing word\n",
    "#     missing_word_embedding = model.encode(row[\"MoodTag\"], convert_to_tensor=True)\n",
    "    \n",
    "#     # Compute similarity with available words\n",
    "#     similarities = util.cos_sim(missing_word_embedding, available_embeddings).squeeze()\n",
    "#     # Compute similarity with available words\n",
    "#     # similarities = util.cos_sim(missing_word_embedding, available_embeddings).squeeze()\n",
    "\n",
    "#     # Move similarity tensor to CPU before processing\n",
    "#     similarities = similarities.cpu().numpy()  # Convert to NumPy array\n",
    "    \n",
    "#     # Find the most similar word\n",
    "#     best_match_idx = np.argmax(similarities)\n",
    "#     best_match_word = available_data.iloc[best_match_idx]\n",
    "#     print(best_match_word)\n",
    "    \n",
    "#     # Assign valence and arousal scores\n",
    "#     missing_data.at[idx, \"Valence\"] = best_match_word[\"Valence\"]\n",
    "#     missing_data.at[idx, \"Arousal\"] = best_match_word[\"Arousal\"]\n",
    "\n",
    "# # Combine the datasets\n",
    "# data_filled = pd.concat([available_data, missing_data]).sort_index()\n",
    "\n",
    "# # Save the updated dataset\n",
    "# data_filled.to_csv(\"moodtag_valence_arousal_filled_similarity.csv\", index=False)\n",
    "\n",
    "# print(\"Missing values filled using similarity scores. Updated dataset saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('fast.n.01'), Synset('fast.v.01'), Synset('fast.v.02'), Synset('fast.a.01'), Synset('fast.a.02'), Synset('fast.a.03'), Synset('fast.s.04'), Synset('fast.s.05'), Synset('debauched.s.01'), Synset('flying.s.02'), Synset('fast.s.08'), Synset('firm.s.10'), Synset('fast.s.10'), Synset('fast.r.01'), Synset('fast.r.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "word = \"fast\"\n",
    "word_synsets = wordnet.synsets(word)\n",
    "\n",
    "print(word_synsets)\n",
    "# similar_word_synsets = wordnet.synsets(similar_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 6 fields in line 11, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the track-tag file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m track_tag_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/autotagging_moodtheme-train.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Process tags for each track\u001b[39;00m\n\u001b[1;32m      8\u001b[0m track_tag_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAGS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m track_tag_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAGS\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/music2emo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/music2emo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/music2emo/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/micromamba/envs/music2emo/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 6 fields in line 11, saw 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the track-tag file\n",
    "track_tag_df = pd.read_csv(\"../data/autotagging_moodtheme-train.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Process tags for each track\n",
    "track_tag_df[\"TAGS\"] = track_tag_df[\"TAGS\"].str.split(\"\\t\")\n",
    "\n",
    "# Create a dictionary to store co-occurrences\n",
    "co_occurrence = defaultdict(list)\n",
    "\n",
    "# Populate the co-occurrence dictionary\n",
    "for tags in track_tag_df[\"TAGS\"]:\n",
    "    for tag in tags:\n",
    "        co_occurrence[tag].extend([t for t in tags if t != tag])\n",
    "\n",
    "# Compute most frequent co-occurring tags\n",
    "co_occurrence_counts = {\n",
    "    tag: pd.Series(co_tags).value_counts().to_dict()\n",
    "    for tag, co_tags in co_occurrence.items()\n",
    "}\n",
    "\n",
    "# Load mood tag valence/arousal data\n",
    "moodtag_data = pd.read_csv(\"moodtag_valence_arousal_scores.csv\")\n",
    "\n",
    "# Identify missing tags\n",
    "missing_tags = moodtag_data[moodtag_data[\"Valence\"].isna() | moodtag_data[\"Arousal\"].isna()][\"MoodTag\"]\n",
    "\n",
    "# Fill in missing data based on co-occurring tags\n",
    "for missing_tag in missing_tags:\n",
    "    co_tags = co_occurrence_counts.get(missing_tag, {})\n",
    "    if co_tags:\n",
    "        # Find the most frequent co-occurring tag\n",
    "        most_common_tag = max(co_tags, key=co_tags.get)\n",
    "        # Use its valence and arousal as a proxy\n",
    "        replacement_row = moodtag_data[moodtag_data[\"MoodTag\"] == most_common_tag]\n",
    "        if not replacement_row.empty:\n",
    "            valence = replacement_row[\"Valence\"].values[0]\n",
    "            arousal = replacement_row[\"Arousal\"].values[0]\n",
    "            moodtag_data.loc[moodtag_data[\"MoodTag\"] == missing_tag, [\"Valence\", \"Arousal\"]] = [valence, arousal]\n",
    "\n",
    "# Save the updated file\n",
    "moodtag_data.to_csv(\"updated_moodtag_valence_arousal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoodTag  song_id    action  adventure  advertising  background    ballad  \\\n",
      "0              1  0.015241   0.013587     0.025134    0.022564  0.019407   \n",
      "1              4  0.015384   0.013752     0.024744    0.022351  0.019349   \n",
      "2              5  0.015429   0.013819     0.024586    0.022261  0.019351   \n",
      "3              6  0.015345   0.013651     0.024977    0.022488  0.019294   \n",
      "4              7  0.015142   0.013417     0.025544    0.022794  0.019358   \n",
      "\n",
      "MoodTag      calm  children  christmas  commercial  ...      slow      soft  \\\n",
      "0        0.020658  0.016641   0.013148    0.022429  ...  0.029547  0.018438   \n",
      "1        0.020572  0.016719   0.013311    0.022298  ...  0.028804  0.018425   \n",
      "2        0.020633  0.016749   0.013388    0.022189  ...  0.028492  0.018467   \n",
      "3        0.020292  0.016676   0.013179    0.022562  ...  0.029304  0.018270   \n",
      "4        0.020346  0.016562   0.012945    0.022773  ...  0.030421  0.018257   \n",
      "\n",
      "MoodTag  soundscape     space     sport    summer   trailer    travel  \\\n",
      "0          0.018897  0.018165  0.016373  0.014557  0.027652  0.014024   \n",
      "1          0.018866  0.018163  0.016449  0.014690  0.027055  0.014168   \n",
      "2          0.018872  0.018193  0.016490  0.014752  0.026827  0.014237   \n",
      "3          0.018816  0.018056  0.016365  0.014585  0.027370  0.014048   \n",
      "4          0.018846  0.018039  0.016250  0.014391  0.028239  0.013838   \n",
      "\n",
      "MoodTag    upbeat  uplifting  \n",
      "0        0.015770   0.016373  \n",
      "1        0.015865   0.016449  \n",
      "2        0.015914   0.016490  \n",
      "3        0.015773   0.016365  \n",
      "4        0.015629   0.016250  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Load mood tags and VA scores\n",
    "moodtag_file = \"../data/moodtag_va_scores.csv\"\n",
    "mood_df = pd.read_csv(moodtag_file)\n",
    "\n",
    "# Load static annotations with VA scores for songs\n",
    "static_annotations_file = \"../data/static_annotations.csv\"\n",
    "annotations_df = pd.read_csv(static_annotations_file)\n",
    "\n",
    "\n",
    "\n",
    "# Standardize the VA scores for both mood tags and the song annotations\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform moodtag VA scores\n",
    "mood_va_scaled = scaler.fit_transform(mood_df[['Valence', 'Arousal']])\n",
    "mood_df[['Valence_Scaled', 'Arousal_Scaled']] = mood_va_scaled\n",
    "\n",
    "# Transform song annotations VA scores\n",
    "annotations_va_scaled = scaler.transform(annotations_df[['valence_mean', 'arousal_mean']].rename(\n",
    "    columns={'valence_mean': 'Valence', 'arousal_mean': 'Arousal'}\n",
    "))\n",
    "annotations_df[['valence_scaled', 'arousal_scaled']] = annotations_va_scaled\n",
    "\n",
    "# Use pairwise distances to compute similarity\n",
    "distances = pairwise_distances(annotations_df[['valence_scaled', 'arousal_scaled']], mood_va_scaled)\n",
    "\n",
    "# Convert distances to probabilities using inverse distance weighting\n",
    "probabilities = 1 / (distances + 1e-6)  # Add small value to avoid division by zero\n",
    "probabilities = probabilities / probabilities.sum(axis=1, keepdims=True)  # Normalize to sum to 1\n",
    "\n",
    "# Create a DataFrame with the probabilities\n",
    "prob_df = pd.DataFrame(probabilities, columns=mood_df['MoodTag'], index=annotations_df['song_id'])\n",
    "\n",
    "# Add the song IDs as a column\n",
    "prob_df.reset_index(inplace=True)\n",
    "prob_df.rename(columns={'index': 'song_id'}, inplace=True)\n",
    "\n",
    "# Save the probabilities to a CSV file\n",
    "output_file = \"song_mood_probabilities.csv\"\n",
    "prob_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the first few rows of the probability DataFrame\n",
    "print(prob_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "mood_df = pd.read_csv(\"../data/moodtag_va_scores.csv\")\n",
    "annotations_df = pd.read_csv(\"../data/static_annotations.csv\")\n",
    "\n",
    "# Standardize the Valence and Arousal scores\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Rename columns in annotations_df to match those in mood_df\n",
    "annotations_renamed = annotations_df.rename(columns={'valence_mean': 'Valence', 'arousal_mean': 'Arousal'})\n",
    "\n",
    "# Fit and transform using the scaler\n",
    "mood_va_scaled = scaler.fit_transform(mood_df[['Valence', 'Arousal']])\n",
    "annotations_va_scaled = scaler.transform(annotations_renamed[['Valence', 'Arousal']])\n",
    "\n",
    "# Compute cosine similarity (returns values between -1 and 1)\n",
    "cosine_similarities = cosine_similarity(annotations_va_scaled, mood_va_scaled)\n",
    "\n",
    "# Apply a log transformation to enhance differentiation\n",
    "log_transformed_similarities = np.log(cosine_similarities - np.min(cosine_similarities) + 1)\n",
    "\n",
    "# Normalize the transformed similarities to [0, 1] range\n",
    "normalized_similarities = (log_transformed_similarities - np.min(log_transformed_similarities)) / (np.max(log_transformed_similarities) - np.min(log_transformed_similarities))\n",
    "\n",
    "# Apply Softmax to the similarities (converts scores into a probability distribution)\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "probabilities = softmax(normalized_similarities)\n",
    "\n",
    "# Apply Top-N selection (e.g., Top 3 mood tags per song)\n",
    "top_n = 3\n",
    "top_n_indices = np.argsort(probabilities, axis=1)[:, -top_n:]  # Get indices of top N tags for each song\n",
    "binary_labels = np.zeros_like(probabilities)\n",
    "\n",
    "# Mark the top N tags as 1 (indicating the song's mood)\n",
    "for i, indices in enumerate(top_n_indices):\n",
    "    binary_labels[i, indices] = 1\n",
    "\n",
    "# Map probabilities to DataFrame\n",
    "prob_df = pd.DataFrame(probabilities, columns=mood_df['MoodTag'])\n",
    "prob_df['song_id'] = annotations_df['song_id']\n",
    "\n",
    "# Reorder so that song_id is the first column\n",
    "prob_df = prob_df[['song_id'] + [col for col in prob_df.columns if col != 'song_id']]\n",
    "\n",
    "# Map binary labels to DataFrame\n",
    "binary_df = pd.DataFrame(binary_labels, columns=mood_df['MoodTag'])\n",
    "binary_df['song_id'] = annotations_df['song_id']\n",
    "\n",
    "# Reorder so that song_id is the first column\n",
    "binary_df = binary_df[['song_id'] + [col for col in binary_df.columns if col != 'song_id']]\n",
    "\n",
    "# Save results to CSV\n",
    "prob_df.to_csv(\"song_mood_ml_probabilities.csv\", index=False)\n",
    "binary_df.to_csv(\"song_mood_binary_labels.csv\", index=False)\n",
    "\n",
    "print(\"CSV files saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   song_id    action  adventure  advertising  background    ballad      calm  \\\n",
      "0      2.0  0.013240   0.004248     0.168030    0.112856  0.036081  0.017696   \n",
      "1      3.0  0.021431   0.006984     0.234862    0.168885  0.054896  0.022720   \n",
      "2      4.0  0.320299   0.129527     0.077959    0.125427  0.119022  0.017800   \n",
      "3      5.0  0.138134   0.039858     0.112143    0.147440  0.070966  0.012105   \n",
      "4      7.0  0.428004   0.167912     0.034119    0.055664  0.054696  0.007737   \n",
      "\n",
      "   children  christmas  commercial  ...      slow      soft  soundscape  \\\n",
      "0  0.020384   0.002435    0.147957  ...  0.287676  0.017461    0.033591   \n",
      "1  0.033119   0.003988    0.216847  ...  0.343755  0.025598    0.052026   \n",
      "2  0.314971   0.062985    0.128252  ...  0.042500  0.054918    0.145118   \n",
      "3  0.122258   0.017722    0.285557  ...  0.079954  0.028084    0.080912   \n",
      "4  0.193930   0.067977    0.069424  ...  0.018991  0.026246    0.068584   \n",
      "\n",
      "      space     sport    summer   trailer    travel    upbeat  uplifting  \n",
      "0  0.021099  0.014649  0.006364  0.206137  0.004379  0.011284   0.014649  \n",
      "1  0.032194  0.023586  0.010400  0.260733  0.007153  0.018267   0.023586  \n",
      "2  0.096051  0.184812  0.141838  0.050484  0.100600  0.174737   0.184812  \n",
      "3  0.046754  0.067885  0.042892  0.079415  0.029342  0.059177   0.067885  \n",
      "4  0.047215  0.113806  0.126421  0.021847  0.094813  0.119571   0.113806  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# # Load moodtag_va_scores.csv and static_annotations.csv\n",
    "# moodtags_df = pd.read_csv('../data/moodtag_va_scores.csv')\n",
    "\n",
    "# annotations_df = pd.read_csv('../meta/static_annotations_deam.csv')\n",
    "# # Function to calculate sigmoid of distance\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# # Function to calculate Euclidean distance between VA values, adjusted by standard deviation\n",
    "# def calculate_distance(valence1, arousal1, valence2, arousal2, valence_std, arousal_std):\n",
    "#     # Scale the distance by the standard deviations to make it more sensitive to smaller variability\n",
    "#     distance = np.sqrt((valence1 - valence2) ** 2 + (arousal1 - arousal2) ** 2)\n",
    "#     # Adjust the distance by the standard deviations\n",
    "#     #scaled_distance = distance / (valence_std + arousal_std)\n",
    "#     return distance\n",
    "\n",
    "# # Initialize a DataFrame to store mood tag probabilities\n",
    "# mood_probabilities = []\n",
    "# # scale_factor = 0.5\n",
    "# # max_distance = 3\n",
    "# # For each song in annotations_df, calculate probabilities for each mood tag\n",
    "# for index, row in annotations_df.iterrows():\n",
    "#     song_id = row['song_id']\n",
    "#     valence_mean = row['valence_mean']\n",
    "#     arousal_mean = row['arousal_mean']\n",
    "#     valence_std = row['valence_std']\n",
    "#     arousal_std = row['arousal_std']\n",
    "    \n",
    "#     probabilities = {}\n",
    "#     distancelist = []\n",
    "#     problist = []\n",
    "\n",
    "#     for _, moodtag_row in moodtags_df.iterrows():\n",
    "#         mood_tag = moodtag_row['MoodTag']\n",
    "#         mood_valence = moodtag_row['Valence']\n",
    "#         mood_arousal = moodtag_row['Arousal']\n",
    "        \n",
    "#         # Compute distance and map it to a probability using sigmoid, adjusted by std\n",
    "#         distance = calculate_distance(valence_mean, arousal_mean, mood_valence, mood_arousal, valence_std, arousal_std)\n",
    "        \n",
    "#         # distancelist.append(distance)\n",
    "#         # if distance > 4:\n",
    "#         #     distance = 4.0\n",
    "#         # shifted_distance = (distance - max_distance / 2) / (max_distance / 2)  # Normalize to [-1, 1]\n",
    "        \n",
    "#         prob = sigmoid(-distance)\n",
    "#         prob = prob * 2.0\n",
    "#         problist.append(prob)\n",
    "        \n",
    "#         probabilities[mood_tag] = prob  # Store the probability for the current mood tag\n",
    "\n",
    "#     # sorted_list = sorted(problist, reverse = True) \n",
    "#     # print(sorted_list)\n",
    "#     # Store the results for the current song\n",
    "#     mood_probabilities.append({'song_id': song_id, **probabilities})\n",
    "\n",
    "# # Convert the mood probabilities list into a DataFrame\n",
    "# probability_df = pd.DataFrame(mood_probabilities)\n",
    "\n",
    "# # Optionally, you can save the result to a CSV file\n",
    "# probability_df.to_csv('../meta/mood_probabilities_deam.csv', index=False)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# # print(probability_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "moodtags_df = pd.read_csv('../data/moodtag_va_scores.csv')\n",
    "annotations_df = pd.read_csv('../meta/static_annotations_pmemo_scaled.csv')\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def calculate_distance(valence1, arousal1, valence2, arousal2, valence_std, arousal_std):\n",
    "    distance = np.sqrt((valence1 - valence2) ** 2 + (arousal1 - arousal2) ** 2)\n",
    "    return distance\n",
    "\n",
    "mood_probabilities = []\n",
    "for index, row in annotations_df.iterrows():\n",
    "    song_id = row['song_id']\n",
    "    valence_mean = row['valence_mean']\n",
    "    arousal_mean = row['arousal_mean']\n",
    "    valence_std = row['valence_std']\n",
    "    arousal_std = row['arousal_std']\n",
    "    \n",
    "    probabilities = {}\n",
    "    for _, moodtag_row in moodtags_df.iterrows():\n",
    "        mood_tag = moodtag_row['MoodTag']\n",
    "        mood_valence = moodtag_row['Valence']\n",
    "        mood_arousal = moodtag_row['Arousal']\n",
    "        \n",
    "        distance = calculate_distance(valence_mean, arousal_mean, mood_valence, mood_arousal, valence_std, arousal_std)        \n",
    "        prob = sigmoid(-distance)\n",
    "        prob = prob * 2.0\n",
    "        \n",
    "        probabilities[mood_tag] = prob  # Store the probability for the current mood tag\n",
    "\n",
    "    mood_probabilities.append({'song_id': int(song_id), **probabilities})\n",
    "\n",
    "probability_df = pd.DataFrame(mood_probabilities)\n",
    "probability_df.to_csv('../meta/mood_probabilities_pmemo_scaled.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete. Scaled data saved to 'static_annotations_pmemo_scaled.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"../meta/static_annotations_pmemo.csv\")\n",
    "\n",
    "# Define the transformation function\n",
    "def scale_range(value, old_min, old_max, new_min, new_max):\n",
    "    return ((value - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min\n",
    "\n",
    "# Scale valence_mean and arousal_mean from 01 to 19\n",
    "data['valence_mean'] = data['valence_mean'].apply(scale_range, args=(0, 1, 1, 9))\n",
    "data['arousal_mean'] = data['arousal_mean'].apply(scale_range, args=(0, 1, 1, 9))\n",
    "\n",
    "# Save the transformed data to a new CSV file\n",
    "data.to_csv(\"../meta/static_annotations_pmemo_scaled.csv\", index=False)\n",
    "\n",
    "print(\"Transformation complete. Scaled data saved to 'static_annotations_pmemo_scaled.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "def parse_chord_file(file_path):\n",
    "    \"\"\"\n",
    "    Parse a chord file to extract a list of chord sequences, ignoring 'N'.\n",
    "    Splits sequences whenever an 'N' is encountered.\n",
    "    \"\"\"\n",
    "    chords_list = []  # List of chord sequences\n",
    "    current_sequence = []  # Current sequence of chords\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3:\n",
    "                start, end, chord = parts\n",
    "                if chord != 'N':  # Ignore 'N' (no chord)\n",
    "                    current_sequence.append(chord)\n",
    "                else:\n",
    "                    if len(current_sequence) > 0:\n",
    "                        chords_list.append(current_sequence)\n",
    "                        current_sequence = []\n",
    "\n",
    "    # Add the last sequence if it exists\n",
    "    if len(current_sequence) > 0:\n",
    "        chords_list.append(current_sequence)\n",
    "\n",
    "    return chords_list\n",
    "\n",
    "def generate_ngram_vocab(files, n):\n",
    "    \"\"\"\n",
    "    Generate n-gram vocabulary from a list of chord files.\n",
    "    Each file can contain multiple chord sequences.\n",
    "    \"\"\"\n",
    "    ngram_set = set()\n",
    "\n",
    "    for file_path in files:\n",
    "        chord_sequences = parse_chord_file(file_path)\n",
    "        \n",
    "        for chord_sequence in chord_sequences:\n",
    "            # Generate n-grams for the current chord sequence\n",
    "            ngrams = [tuple(chord_sequence[i:i + n]) for i in range(len(chord_sequence) - n + 1)]\n",
    "            ngram_set.update(ngrams)\n",
    "\n",
    "    # Create a mapping from n-grams to unique indices\n",
    "    ngram_vocab = {ngram: idx for idx, ngram in enumerate(sorted(ngram_set))}\n",
    "    return ngram_vocab\n",
    "\n",
    "\n",
    "file_directory1 = \"../../dataset/jamendo/chord/lab3\"\n",
    "file_directory2 = \"../../dataset/deam/chord/lab3\"\n",
    "file_directory3 = \"../../dataset/pmemo/chord/lab3\"\n",
    "file_directory4 = \"../../dataset/emomusic/chord/lab3\"\n",
    "\n",
    "# Use glob to handle recursive file search\n",
    "chord_files1 = glob.glob(os.path.join(file_directory1, \"*/*.lab\"))\n",
    "chord_files2 = glob.glob(os.path.join(file_directory2, \"*.lab\"))\n",
    "chord_files3 = glob.glob(os.path.join(file_directory3, \"*.lab\"))\n",
    "chord_files4 = glob.glob(os.path.join(file_directory4, \"*.lab\"))\n",
    "\n",
    "all_chord_files = chord_files1 + chord_files2 + chord_files3 + chord_files4\n",
    "\n",
    "# chord_files1 = [os.path.join(file_directory1, f) for f in os.listdir(file_directory1) if f.endswith('.lab')]\n",
    "# chord_files2= [os.path.join(file_directory2, f) for f in os.listdir(file_directory2) if f.endswith('.lab')]\n",
    "# chord_files3 = [os.path.join(file_directory3, f) for f in os.listdir(file_directory3) if f.endswith('.lab')]\n",
    "# chord_files4 = [os.path.join(file_directory4, f) for f in os.listdir(file_directory4) if f.endswith('.lab')]\n",
    "\n",
    "\n",
    "n = 2  # For bigrams\n",
    "ngram_vocab = generate_ngram_vocab(all_chord_files, n)\n",
    "\n",
    "# # Output vocabulary\n",
    "# print(ngram_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9979"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngram_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music2emo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
